{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression using IMDB Reviews (large) datasets\n",
    "\n",
    "The source of this dataset can be accessed through the following link: http://ai.stanford.edu/~amaas/data/sentiment/\n",
    "This dataset provides data for train and test. Each of dataset contains 25,000 instances.\n",
    "\n",
    "In this program, we are using the Count Vectorizer to count the text frequency given in the datasets. Thus, for the sake of simplicity, we limited the maximum number of feature by 10,000. In this way, we could transform the matrix to dense for further scaling the data using the StandardScaler by sklearn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import graphviz\n",
    "from sklearn import linear_model\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.cross_validation import train_test_split, ShuffleSplit\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "from prettytable import PrettyTable\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_imdb(path):\n",
    "    \n",
    "    print(\"Loading the imdb data\")\n",
    "    \n",
    "    train_neg_files = glob.glob(path+\"/train/neg/*.txt\")\n",
    "    train_pos_files = glob.glob(path+\"/train/pos/*.txt\")\n",
    "    \n",
    "    X_train_corpus = []\n",
    "    y_train = []\n",
    "    \n",
    "    for tnf in train_neg_files:\n",
    "        f = open(tnf, 'r', encoding=\"utf8\")\n",
    "        line = f.read()\n",
    "        X_train_corpus.append(line)\n",
    "        y_train.append(0)\n",
    "        f.close()\n",
    "    \n",
    "    for tpf in train_pos_files:\n",
    "        f = open(tpf, 'r', encoding=\"utf8\")\n",
    "        line = f.read()\n",
    "        X_train_corpus.append(line)\n",
    "        y_train.append(1)\n",
    "        f.close()\n",
    "    \n",
    "    print(\"Train Data loaded.\")\n",
    "    \n",
    "    test_neg_files = glob.glob(path+\"/test/neg/*.txt\")\n",
    "    test_pos_files = glob.glob(path+\"/test/pos/*.txt\")\n",
    "    \n",
    "    X_test_corpus = []\n",
    "    y_test = []\n",
    "    \n",
    "    for tnf in test_neg_files:\n",
    "        f = open(tnf, 'r', encoding=\"utf8\")\n",
    "        X_test_corpus.append(f.read())\n",
    "        y_test.append(0)\n",
    "        f.close()\n",
    "    \n",
    "    for tpf in test_pos_files:\n",
    "        f = open(tpf, 'r', encoding=\"utf8\")\n",
    "        X_test_corpus.append(f.read())\n",
    "        y_test.append(1)\n",
    "        f.close()\n",
    "    \n",
    "    print(\"Test Data loaded.\")\n",
    "    \n",
    "    y_train = np.array(y_train)\n",
    "    y_test = np.array(y_test)\n",
    "    \n",
    "    return X_train_corpus, y_train, X_test_corpus , y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the imdb data\n",
      "Train Data loaded.\n",
      "Test Data loaded.\n"
     ]
    }
   ],
   "source": [
    "X_train_corpus , y_train, X_test_corpus , y_test = load_imdb('./aclImdb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binarize the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Vectorizer Transform start\n",
      "\n",
      "Train Data Transformed\n",
      "Train Data size  (25000, 10000)\n",
      "\n",
      "Test Data Transformed\n",
      "Test Data size  (25000, 10000)\n"
     ]
    }
   ],
   "source": [
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "tf_vectorizer = CountVectorizer(max_df=1.0, min_df=2, max_features = 10000, binary=True)\n",
    "\n",
    "print('Data Vectorizer Transform start')\n",
    "print()\n",
    "X_train = tf_vectorizer.fit_transform(X_train_corpus)\n",
    "\n",
    "print('Train Data Transformed')\n",
    "print('Train Data size ', X_train.shape)\n",
    "print()\n",
    "X_test = tf_vectorizer.transform(X_test_corpus)\n",
    "print('Test Data Transformed')\n",
    "print('Test Data size ', X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_names = tf_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the Model to the Data without Z-score scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_noz_l2 = LogisticRegression()\n",
    "clf_noz_l2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idx_noz_l2 = np.argsort(np.absolute(clf_noz_l2.coef_)[0,:])[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_noz_l1 = LogisticRegression(penalty='l1')\n",
    "clf_noz_l1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idx_noz_l1 = np.argsort(np.absolute(clf_noz_l1.coef_)[0,:])[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L2 and L1-regularized Logistic Regression Classifier without z-scoring\n",
      "Top 10 features and weights (with absolute value)\n",
      "\n",
      "+------+----------------+-----------+--------------+-----------+\n",
      "| Rank |  L2 Features   | L2 Weight | L1 Features  | L1 Weight |\n",
      "+------+----------------+-----------+--------------+-----------+\n",
      "|  1   |     waste      |   -2.376  |    wayans    |   -4.092  |\n",
      "|  2   |     worst      |  -2.3141  |  vengeance   |   3.2444  |\n",
      "|  3   | disappointment |  -2.2132  |    greene    |   3.0828  |\n",
      "|  4   |     poorly     |  -2.0917  |   cerebral   |   3.0481  |\n",
      "|  5   |    unfunny     |  -1.9441  | abomination  |  -2.9887  |\n",
      "|  6   |     refer      |  -1.8773  |    finely    |   2.8862  |\n",
      "|  7   |   vengeance    |   1.8422  |   lifeless   |  -2.8083  |\n",
      "|  8   |  appreciated   |   1.8079  |     café     |   2.7891  |\n",
      "|  9   |    cerebral    |   1.7976  | unremarkable |  -2.7793  |\n",
      "|  10  |   laughable    |  -1.7907  |    refer     |  -2.7116  |\n",
      "+------+----------------+-----------+--------------+-----------+\n"
     ]
    }
   ],
   "source": [
    "### Print on Pretty Table\n",
    "lr_noz = PrettyTable(['Rank', 'L2 Features', 'L2 Weight', 'L1 Features', 'L1 Weight'])\n",
    "\n",
    "for idx in range(0,10):\n",
    "    lr_noz.add_row([idx+1, f_names[idx_noz_l2[idx]], np.around(clf_noz_l2.coef_[0,idx_noz_l2[idx]], decimals=4), f_names[idx_noz_l1[idx]], np.around(clf_noz_l1.coef_[0,idx_noz_l1[idx]], decimals=4)])\n",
    "\n",
    "print('L2 and L1-regularized Logistic Regression Classifier without z-scoring')\n",
    "print('Top 10 features and weights (with absolute value)')\n",
    "print()\n",
    "print(lr_noz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\r\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n",
       "<!-- Generated by graphviz version 2.38.0 (20140413.2041)\r\n",
       " -->\r\n",
       "<!-- Title: Tree Pages: 1 -->\r\n",
       "<svg width=\"719pt\" height=\"685pt\"\r\n",
       " viewBox=\"0.00 0.00 719.00 685.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 681)\">\r\n",
       "<title>Tree</title>\r\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-681 715,-681 715,4 -4,4\"/>\r\n",
       "<!-- 0 -->\r\n",
       "<g id=\"node1\" class=\"node\"><title>0</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M622.5,-677C622.5,-677 483.5,-677 483.5,-677 477.5,-677 471.5,-671 471.5,-665 471.5,-665 471.5,-621 471.5,-621 471.5,-615 477.5,-609 483.5,-609 483.5,-609 622.5,-609 622.5,-609 628.5,-609 634.5,-615 634.5,-621 634.5,-621 634.5,-665 634.5,-665 634.5,-671 628.5,-677 622.5,-677\"/>\r\n",
       "<text text-anchor=\"start\" x=\"523\" y=\"-661.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">bad ≤ 0.5</text>\r\n",
       "<text text-anchor=\"start\" x=\"524\" y=\"-646.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.5</text>\r\n",
       "<text text-anchor=\"start\" x=\"497\" y=\"-631.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 25000</text>\r\n",
       "<text text-anchor=\"start\" x=\"479.5\" y=\"-616.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [12500, 12500]</text>\r\n",
       "</g>\r\n",
       "<!-- 1 -->\r\n",
       "<g id=\"node2\" class=\"node\"><title>1</title>\r\n",
       "<path fill=\"#399de5\" fill-opacity=\"0.262745\" stroke=\"black\" d=\"M534.5,-573C534.5,-573 403.5,-573 403.5,-573 397.5,-573 391.5,-567 391.5,-561 391.5,-561 391.5,-517 391.5,-517 391.5,-511 397.5,-505 403.5,-505 403.5,-505 534.5,-505 534.5,-505 540.5,-505 546.5,-511 546.5,-517 546.5,-517 546.5,-561 546.5,-561 546.5,-567 540.5,-573 534.5,-573\"/>\r\n",
       "<text text-anchor=\"start\" x=\"434\" y=\"-557.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">worst ≤ 0.5</text>\r\n",
       "<text text-anchor=\"start\" x=\"431.5\" y=\"-542.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.488</text>\r\n",
       "<text text-anchor=\"start\" x=\"413\" y=\"-527.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 19096</text>\r\n",
       "<text text-anchor=\"start\" x=\"399.5\" y=\"-512.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [8094, 11002]</text>\r\n",
       "</g>\r\n",
       "<!-- 0&#45;&gt;1 -->\r\n",
       "<g id=\"edge1\" class=\"edge\"><title>0&#45;&gt;1</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M525.728,-608.884C518.465,-600.065 510.531,-590.43 502.958,-581.235\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"505.482,-578.794 496.423,-573.299 500.078,-583.244 505.482,-578.794\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"494.015\" y=\"-594.483\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">True</text>\r\n",
       "</g>\r\n",
       "<!-- 12 -->\r\n",
       "<g id=\"node13\" class=\"node\"><title>12</title>\r\n",
       "<path fill=\"#e58139\" fill-opacity=\"0.658824\" stroke=\"black\" d=\"M699,-565.5C699,-565.5 577,-565.5 577,-565.5 571,-565.5 565,-559.5 565,-553.5 565,-553.5 565,-524.5 565,-524.5 565,-518.5 571,-512.5 577,-512.5 577,-512.5 699,-512.5 699,-512.5 705,-512.5 711,-518.5 711,-524.5 711,-524.5 711,-553.5 711,-553.5 711,-559.5 705,-565.5 699,-565.5\"/>\r\n",
       "<text text-anchor=\"start\" x=\"600.5\" y=\"-550.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.379</text>\r\n",
       "<text text-anchor=\"start\" x=\"586.5\" y=\"-535.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 5904</text>\r\n",
       "<text text-anchor=\"start\" x=\"573\" y=\"-520.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [4406, 1498]</text>\r\n",
       "</g>\r\n",
       "<!-- 0&#45;&gt;12 -->\r\n",
       "<g id=\"edge12\" class=\"edge\"><title>0&#45;&gt;12</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M580.597,-608.884C590.037,-597.556 600.6,-584.88 610.066,-573.521\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"613.02,-575.443 616.733,-565.52 607.643,-570.962 613.02,-575.443\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"618.997\" y=\"-586.717\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">False</text>\r\n",
       "</g>\r\n",
       "<!-- 2 -->\r\n",
       "<g id=\"node3\" class=\"node\"><title>2</title>\r\n",
       "<path fill=\"#399de5\" fill-opacity=\"0.349020\" stroke=\"black\" d=\"M452.5,-469C452.5,-469 321.5,-469 321.5,-469 315.5,-469 309.5,-463 309.5,-457 309.5,-457 309.5,-413 309.5,-413 309.5,-407 315.5,-401 321.5,-401 321.5,-401 452.5,-401 452.5,-401 458.5,-401 464.5,-407 464.5,-413 464.5,-413 464.5,-457 464.5,-457 464.5,-463 458.5,-469 452.5,-469\"/>\r\n",
       "<text text-anchor=\"start\" x=\"350.5\" y=\"-453.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">waste ≤ 0.5</text>\r\n",
       "<text text-anchor=\"start\" x=\"349.5\" y=\"-438.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.477</text>\r\n",
       "<text text-anchor=\"start\" x=\"331\" y=\"-423.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 17866</text>\r\n",
       "<text text-anchor=\"start\" x=\"317.5\" y=\"-408.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [7032, 10834]</text>\r\n",
       "</g>\r\n",
       "<!-- 1&#45;&gt;2 -->\r\n",
       "<g id=\"edge2\" class=\"edge\"><title>1&#45;&gt;2</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M442.377,-504.884C435.288,-496.065 427.542,-486.43 420.15,-477.235\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"422.764,-474.9 413.77,-469.299 417.308,-479.286 422.764,-474.9\"/>\r\n",
       "</g>\r\n",
       "<!-- 11 -->\r\n",
       "<g id=\"node12\" class=\"node\"><title>11</title>\r\n",
       "<path fill=\"#e58139\" fill-opacity=\"0.843137\" stroke=\"black\" d=\"M609,-461.5C609,-461.5 495,-461.5 495,-461.5 489,-461.5 483,-455.5 483,-449.5 483,-449.5 483,-420.5 483,-420.5 483,-414.5 489,-408.5 495,-408.5 495,-408.5 609,-408.5 609,-408.5 615,-408.5 621,-414.5 621,-420.5 621,-420.5 621,-449.5 621,-449.5 621,-455.5 615,-461.5 609,-461.5\"/>\r\n",
       "<text text-anchor=\"start\" x=\"514.5\" y=\"-446.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.236</text>\r\n",
       "<text text-anchor=\"start\" x=\"500.5\" y=\"-431.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1230</text>\r\n",
       "<text text-anchor=\"start\" x=\"491\" y=\"-416.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1062, 168]</text>\r\n",
       "</g>\r\n",
       "<!-- 1&#45;&gt;11 -->\r\n",
       "<g id=\"edge11\" class=\"edge\"><title>1&#45;&gt;11</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M495.948,-504.884C505.165,-493.556 515.48,-480.88 524.723,-469.521\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"527.637,-471.486 531.234,-461.52 522.207,-467.067 527.637,-471.486\"/>\r\n",
       "</g>\r\n",
       "<!-- 3 -->\r\n",
       "<g id=\"node4\" class=\"node\"><title>3</title>\r\n",
       "<path fill=\"#399de5\" fill-opacity=\"0.400000\" stroke=\"black\" d=\"M374.5,-365C374.5,-365 243.5,-365 243.5,-365 237.5,-365 231.5,-359 231.5,-353 231.5,-353 231.5,-309 231.5,-309 231.5,-303 237.5,-297 243.5,-297 243.5,-297 374.5,-297 374.5,-297 380.5,-297 386.5,-303 386.5,-309 386.5,-309 386.5,-353 386.5,-353 386.5,-359 380.5,-365 374.5,-365\"/>\r\n",
       "<text text-anchor=\"start\" x=\"275\" y=\"-349.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">great ≤ 0.5</text>\r\n",
       "<text text-anchor=\"start\" x=\"271.5\" y=\"-334.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.468</text>\r\n",
       "<text text-anchor=\"start\" x=\"253\" y=\"-319.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 17203</text>\r\n",
       "<text text-anchor=\"start\" x=\"239.5\" y=\"-304.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [6438, 10765]</text>\r\n",
       "</g>\r\n",
       "<!-- 2&#45;&gt;3 -->\r\n",
       "<g id=\"edge3\" class=\"edge\"><title>2&#45;&gt;3</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M361.676,-400.884C355,-392.154 347.713,-382.625 340.746,-373.514\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"343.319,-371.117 334.464,-365.299 337.758,-375.369 343.319,-371.117\"/>\r\n",
       "</g>\r\n",
       "<!-- 10 -->\r\n",
       "<g id=\"node11\" class=\"node\"><title>10</title>\r\n",
       "<path fill=\"#e58139\" fill-opacity=\"0.882353\" stroke=\"black\" d=\"M515,-357.5C515,-357.5 417,-357.5 417,-357.5 411,-357.5 405,-351.5 405,-345.5 405,-345.5 405,-316.5 405,-316.5 405,-310.5 411,-304.5 417,-304.5 417,-304.5 515,-304.5 515,-304.5 521,-304.5 527,-310.5 527,-316.5 527,-316.5 527,-345.5 527,-345.5 527,-351.5 521,-357.5 515,-357.5\"/>\r\n",
       "<text text-anchor=\"start\" x=\"428.5\" y=\"-342.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.186</text>\r\n",
       "<text text-anchor=\"start\" x=\"418.5\" y=\"-327.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 663</text>\r\n",
       "<text text-anchor=\"start\" x=\"413\" y=\"-312.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [594, 69]</text>\r\n",
       "</g>\r\n",
       "<!-- 2&#45;&gt;10 -->\r\n",
       "<g id=\"edge10\" class=\"edge\"><title>2&#45;&gt;10</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M412.649,-400.884C421.423,-389.556 431.24,-376.88 440.038,-365.521\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"442.878,-367.569 446.235,-357.52 437.344,-363.283 442.878,-367.569\"/>\r\n",
       "</g>\r\n",
       "<!-- 4 -->\r\n",
       "<g id=\"node5\" class=\"node\"><title>4</title>\r\n",
       "<path fill=\"#399de5\" fill-opacity=\"0.254902\" stroke=\"black\" d=\"M288,-261C288,-261 166,-261 166,-261 160,-261 154,-255 154,-249 154,-249 154,-205 154,-205 154,-199 160,-193 166,-193 166,-193 288,-193 288,-193 294,-193 300,-199 300,-205 300,-205 300,-249 300,-249 300,-255 294,-261 288,-261\"/>\r\n",
       "<text text-anchor=\"start\" x=\"193\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">awful ≤ 0.5</text>\r\n",
       "<text text-anchor=\"start\" x=\"189.5\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.489</text>\r\n",
       "<text text-anchor=\"start\" x=\"171\" y=\"-215.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 12591</text>\r\n",
       "<text text-anchor=\"start\" x=\"162\" y=\"-200.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [5372, 7219]</text>\r\n",
       "</g>\r\n",
       "<!-- 3&#45;&gt;4 -->\r\n",
       "<g id=\"edge4\" class=\"edge\"><title>3&#45;&gt;4</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M282.377,-296.884C275.288,-288.065 267.542,-278.43 260.15,-269.235\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"262.764,-266.9 253.77,-261.299 257.308,-271.286 262.764,-266.9\"/>\r\n",
       "</g>\r\n",
       "<!-- 9 -->\r\n",
       "<g id=\"node10\" class=\"node\"><title>9</title>\r\n",
       "<path fill=\"#399de5\" fill-opacity=\"0.698039\" stroke=\"black\" d=\"M452,-253.5C452,-253.5 330,-253.5 330,-253.5 324,-253.5 318,-247.5 318,-241.5 318,-241.5 318,-212.5 318,-212.5 318,-206.5 324,-200.5 330,-200.5 330,-200.5 452,-200.5 452,-200.5 458,-200.5 464,-206.5 464,-212.5 464,-212.5 464,-241.5 464,-241.5 464,-247.5 458,-253.5 452,-253.5\"/>\r\n",
       "<text text-anchor=\"start\" x=\"353.5\" y=\"-238.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.355</text>\r\n",
       "<text text-anchor=\"start\" x=\"339.5\" y=\"-223.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 4612</text>\r\n",
       "<text text-anchor=\"start\" x=\"326\" y=\"-208.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1066, 3546]</text>\r\n",
       "</g>\r\n",
       "<!-- 3&#45;&gt;9 -->\r\n",
       "<g id=\"edge9\" class=\"edge\"><title>3&#45;&gt;9</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M335.623,-296.884C344.73,-285.556 354.92,-272.88 364.052,-261.521\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"366.946,-263.507 370.484,-253.52 361.491,-259.121 366.946,-263.507\"/>\r\n",
       "</g>\r\n",
       "<!-- 5 -->\r\n",
       "<g id=\"node6\" class=\"node\"><title>5</title>\r\n",
       "<path fill=\"#399de5\" fill-opacity=\"0.305882\" stroke=\"black\" d=\"M212,-157C212,-157 90,-157 90,-157 84,-157 78,-151 78,-145 78,-145 78,-101 78,-101 78,-95 84,-89 90,-89 90,-89 212,-89 212,-89 218,-89 224,-95 224,-101 224,-101 224,-145 224,-145 224,-151 218,-157 212,-157\"/>\r\n",
       "<text text-anchor=\"start\" x=\"113\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">boring ≤ 0.5</text>\r\n",
       "<text text-anchor=\"start\" x=\"113.5\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.484</text>\r\n",
       "<text text-anchor=\"start\" x=\"95\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 12126</text>\r\n",
       "<text text-anchor=\"start\" x=\"86\" y=\"-96.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [4972, 7154]</text>\r\n",
       "</g>\r\n",
       "<!-- 4&#45;&gt;5 -->\r\n",
       "<g id=\"edge5\" class=\"edge\"><title>4&#45;&gt;5</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M202.325,-192.884C195.821,-184.154 188.72,-174.625 181.932,-165.514\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"184.593,-163.227 175.811,-157.299 178.98,-167.409 184.593,-163.227\"/>\r\n",
       "</g>\r\n",
       "<!-- 8 -->\r\n",
       "<g id=\"node9\" class=\"node\"><title>8</title>\r\n",
       "<path fill=\"#e58139\" fill-opacity=\"0.839216\" stroke=\"black\" d=\"M352,-149.5C352,-149.5 254,-149.5 254,-149.5 248,-149.5 242,-143.5 242,-137.5 242,-137.5 242,-108.5 242,-108.5 242,-102.5 248,-96.5 254,-96.5 254,-96.5 352,-96.5 352,-96.5 358,-96.5 364,-102.5 364,-108.5 364,-108.5 364,-137.5 364,-137.5 364,-143.5 358,-149.5 352,-149.5\"/>\r\n",
       "<text text-anchor=\"start\" x=\"269.5\" y=\"-134.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.24</text>\r\n",
       "<text text-anchor=\"start\" x=\"255.5\" y=\"-119.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 465</text>\r\n",
       "<text text-anchor=\"start\" x=\"250\" y=\"-104.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [400, 65]</text>\r\n",
       "</g>\r\n",
       "<!-- 4&#45;&gt;8 -->\r\n",
       "<g id=\"edge8\" class=\"edge\"><title>4&#45;&gt;8</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M251.675,-192.884C260.033,-181.666 269.377,-169.126 277.777,-157.852\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"280.817,-159.63 283.985,-149.52 275.204,-155.448 280.817,-159.63\"/>\r\n",
       "</g>\r\n",
       "<!-- 6 -->\r\n",
       "<g id=\"node7\" class=\"node\"><title>6</title>\r\n",
       "<path fill=\"#399de5\" fill-opacity=\"0.352941\" stroke=\"black\" d=\"M134,-53C134,-53 12,-53 12,-53 6,-53 0,-47 0,-41 0,-41 0,-12 0,-12 0,-6 6,-0 12,-0 12,-0 134,-0 134,-0 140,-0 146,-6 146,-12 146,-12 146,-41 146,-41 146,-47 140,-53 134,-53\"/>\r\n",
       "<text text-anchor=\"start\" x=\"35.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.477</text>\r\n",
       "<text text-anchor=\"start\" x=\"17\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 11549</text>\r\n",
       "<text text-anchor=\"start\" x=\"8\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [4544, 7005]</text>\r\n",
       "</g>\r\n",
       "<!-- 5&#45;&gt;6 -->\r\n",
       "<g id=\"edge6\" class=\"edge\"><title>5&#45;&gt;6</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M123.719,-88.9485C116.244,-79.892 108.136,-70.0682 100.64,-60.9875\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"103.308,-58.721 94.243,-53.2367 97.9094,-63.1769 103.308,-58.721\"/>\r\n",
       "</g>\r\n",
       "<!-- 7 -->\r\n",
       "<g id=\"node8\" class=\"node\"><title>7</title>\r\n",
       "<path fill=\"#e58139\" fill-opacity=\"0.650980\" stroke=\"black\" d=\"M282,-53C282,-53 176,-53 176,-53 170,-53 164,-47 164,-41 164,-41 164,-12 164,-12 164,-6 170,-0 176,-0 176,-0 282,-0 282,-0 288,-0 294,-6 294,-12 294,-12 294,-41 294,-41 294,-47 288,-53 282,-53\"/>\r\n",
       "<text text-anchor=\"start\" x=\"191.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.383</text>\r\n",
       "<text text-anchor=\"start\" x=\"181.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 577</text>\r\n",
       "<text text-anchor=\"start\" x=\"172\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [428, 149]</text>\r\n",
       "</g>\r\n",
       "<!-- 5&#45;&gt;7 -->\r\n",
       "<g id=\"edge7\" class=\"edge\"><title>5&#45;&gt;7</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M178.281,-88.9485C185.756,-79.892 193.864,-70.0682 201.36,-60.9875\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"204.091,-63.1769 207.757,-53.2367 198.692,-58.721 204.091,-63.1769\"/>\r\n",
       "</g>\r\n",
       "</g>\r\n",
       "</svg>\r\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x166b9520588>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_tree = DecisionTreeClassifier(max_depth=6, min_impurity_decrease=0.005)\n",
    "clf_tree.fit(X_train, y_train)\n",
    "\n",
    "tree_plot = tree.export_graphviz(clf_tree, out_file=None, \n",
    "                                      feature_names=f_names, \n",
    "                                      filled=True, rounded=True, \n",
    "                                      special_characters=True) \n",
    "tree_graph_noz = graphviz.Source(tree_plot)\n",
    "tree_graph_noz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result Discussion\n",
    "## Original Data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the Model to the Data with Z-score scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Transform the X_train to dense\n",
    "X_train_dense = X_train.todense()\n",
    "X_test_dense = X_test.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\anne soraya\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\utils\\validation.py:444: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(25000, 10000)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train_dense)\n",
    "X_train_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\anne soraya\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\utils\\validation.py:444: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(25000, 10000)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_scaled = scaler.transform(X_train_dense)\n",
    "X_test_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_l2 = LogisticRegression()\n",
    "clf_l2.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idx_l2 = np.argsort(np.absolute(clf_l2.coef_)[0,:])[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_l1 = LogisticRegression(penalty='l1')\n",
    "clf_l1.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idx_l1 = np.argsort(np.absolute(clf_l1.coef_)[0,:])[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L2 and L1-regularized Logistic Regression Classifier WITH z-scoring\n",
      "Top 10 features and weights (with absolute value)\n",
      "\n",
      "+------+-------------+-----------+-------------+-----------+\n",
      "| Rank | L2 Features | L2 Weight | L1 Features | L1 Weight |\n",
      "+------+-------------+-----------+-------------+-----------+\n",
      "|  1   |    worst    |  -1.3315  |    worst    |  -1.3353  |\n",
      "|  2   |     bad     |   -1.155  |    waste    |  -1.1681  |\n",
      "|  3   |    waste    |   -1.065  |     bad     |  -1.0971  |\n",
      "|  4   |    great    |   0.9473  |  excellent  |   0.8956  |\n",
      "|  5   |  excellent  |   0.9285  |    awful    |  -0.8447  |\n",
      "|  6   |    awful    |   -0.853  |    great    |   0.8152  |\n",
      "|  7   |    boring   |  -0.8322  |   perfect   |   0.7102  |\n",
      "|  8   |   terrible  |  -0.7751  |    boring   |  -0.6985  |\n",
      "|  9   |     best    |   0.7082  |    poorly   |  -0.6732  |\n",
      "|  10  |    worse    |  -0.7064  |     best    |   0.6728  |\n",
      "+------+-------------+-----------+-------------+-----------+\n"
     ]
    }
   ],
   "source": [
    "### Print on Pretty Table\n",
    "lr_woz = PrettyTable(['Rank', 'L2 Features', 'L2 Weight', 'L1 Features', 'L1 Weight'])\n",
    "\n",
    "for idx in range(0,10):\n",
    "    lr_woz.add_row([idx+1, f_names[idx_l2[idx]], np.around(clf_l2.coef_[0,idx_l2[idx]], decimals=4), f_names[idx_l1[idx]], np.around(clf_l1.coef_[0,idx_l1[idx]], decimals=4)])\n",
    "\n",
    "print('L2 and L1-regularized Logistic Regression Classifier WITH z-scoring')\n",
    "print('Top 10 features and weights (with absolute value)')\n",
    "print()\n",
    "print(lr_woz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\r\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n",
       "<!-- Generated by graphviz version 2.38.0 (20140413.2041)\r\n",
       " -->\r\n",
       "<!-- Title: Tree Pages: 1 -->\r\n",
       "<svg width=\"719pt\" height=\"685pt\"\r\n",
       " viewBox=\"0.00 0.00 719.00 685.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 681)\">\r\n",
       "<title>Tree</title>\r\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-681 715,-681 715,4 -4,4\"/>\r\n",
       "<!-- 0 -->\r\n",
       "<g id=\"node1\" class=\"node\"><title>0</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M622.5,-677C622.5,-677 483.5,-677 483.5,-677 477.5,-677 471.5,-671 471.5,-665 471.5,-665 471.5,-621 471.5,-621 471.5,-615 477.5,-609 483.5,-609 483.5,-609 622.5,-609 622.5,-609 628.5,-609 634.5,-615 634.5,-621 634.5,-621 634.5,-665 634.5,-665 634.5,-671 628.5,-677 622.5,-677\"/>\r\n",
       "<text text-anchor=\"start\" x=\"515\" y=\"-661.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">bad ≤ 0.621</text>\r\n",
       "<text text-anchor=\"start\" x=\"524\" y=\"-646.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.5</text>\r\n",
       "<text text-anchor=\"start\" x=\"497\" y=\"-631.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 25000</text>\r\n",
       "<text text-anchor=\"start\" x=\"479.5\" y=\"-616.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [12500, 12500]</text>\r\n",
       "</g>\r\n",
       "<!-- 1 -->\r\n",
       "<g id=\"node2\" class=\"node\"><title>1</title>\r\n",
       "<path fill=\"#399de5\" fill-opacity=\"0.262745\" stroke=\"black\" d=\"M534.5,-573C534.5,-573 403.5,-573 403.5,-573 397.5,-573 391.5,-567 391.5,-561 391.5,-561 391.5,-517 391.5,-517 391.5,-511 397.5,-505 403.5,-505 403.5,-505 534.5,-505 534.5,-505 540.5,-505 546.5,-511 546.5,-517 546.5,-517 546.5,-561 546.5,-561 546.5,-567 540.5,-573 534.5,-573\"/>\r\n",
       "<text text-anchor=\"start\" x=\"426\" y=\"-557.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">worst ≤ 1.425</text>\r\n",
       "<text text-anchor=\"start\" x=\"431.5\" y=\"-542.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.488</text>\r\n",
       "<text text-anchor=\"start\" x=\"413\" y=\"-527.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 19096</text>\r\n",
       "<text text-anchor=\"start\" x=\"399.5\" y=\"-512.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [8094, 11002]</text>\r\n",
       "</g>\r\n",
       "<!-- 0&#45;&gt;1 -->\r\n",
       "<g id=\"edge1\" class=\"edge\"><title>0&#45;&gt;1</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M525.728,-608.884C518.465,-600.065 510.531,-590.43 502.958,-581.235\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"505.482,-578.794 496.423,-573.299 500.078,-583.244 505.482,-578.794\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"494.015\" y=\"-594.483\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">True</text>\r\n",
       "</g>\r\n",
       "<!-- 12 -->\r\n",
       "<g id=\"node13\" class=\"node\"><title>12</title>\r\n",
       "<path fill=\"#e58139\" fill-opacity=\"0.658824\" stroke=\"black\" d=\"M699,-565.5C699,-565.5 577,-565.5 577,-565.5 571,-565.5 565,-559.5 565,-553.5 565,-553.5 565,-524.5 565,-524.5 565,-518.5 571,-512.5 577,-512.5 577,-512.5 699,-512.5 699,-512.5 705,-512.5 711,-518.5 711,-524.5 711,-524.5 711,-553.5 711,-553.5 711,-559.5 705,-565.5 699,-565.5\"/>\r\n",
       "<text text-anchor=\"start\" x=\"600.5\" y=\"-550.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.379</text>\r\n",
       "<text text-anchor=\"start\" x=\"586.5\" y=\"-535.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 5904</text>\r\n",
       "<text text-anchor=\"start\" x=\"573\" y=\"-520.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [4406, 1498]</text>\r\n",
       "</g>\r\n",
       "<!-- 0&#45;&gt;12 -->\r\n",
       "<g id=\"edge12\" class=\"edge\"><title>0&#45;&gt;12</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M580.597,-608.884C590.037,-597.556 600.6,-584.88 610.066,-573.521\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"613.02,-575.443 616.733,-565.52 607.643,-570.962 613.02,-575.443\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"618.997\" y=\"-586.717\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">False</text>\r\n",
       "</g>\r\n",
       "<!-- 2 -->\r\n",
       "<g id=\"node3\" class=\"node\"><title>2</title>\r\n",
       "<path fill=\"#399de5\" fill-opacity=\"0.349020\" stroke=\"black\" d=\"M452.5,-469C452.5,-469 321.5,-469 321.5,-469 315.5,-469 309.5,-463 309.5,-457 309.5,-457 309.5,-413 309.5,-413 309.5,-407 315.5,-401 321.5,-401 321.5,-401 452.5,-401 452.5,-401 458.5,-401 464.5,-407 464.5,-413 464.5,-413 464.5,-457 464.5,-457 464.5,-463 458.5,-469 452.5,-469\"/>\r\n",
       "<text text-anchor=\"start\" x=\"342.5\" y=\"-453.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">waste ≤ 2.014</text>\r\n",
       "<text text-anchor=\"start\" x=\"349.5\" y=\"-438.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.477</text>\r\n",
       "<text text-anchor=\"start\" x=\"331\" y=\"-423.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 17866</text>\r\n",
       "<text text-anchor=\"start\" x=\"317.5\" y=\"-408.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [7032, 10834]</text>\r\n",
       "</g>\r\n",
       "<!-- 1&#45;&gt;2 -->\r\n",
       "<g id=\"edge2\" class=\"edge\"><title>1&#45;&gt;2</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M442.377,-504.884C435.288,-496.065 427.542,-486.43 420.15,-477.235\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"422.764,-474.9 413.77,-469.299 417.308,-479.286 422.764,-474.9\"/>\r\n",
       "</g>\r\n",
       "<!-- 11 -->\r\n",
       "<g id=\"node12\" class=\"node\"><title>11</title>\r\n",
       "<path fill=\"#e58139\" fill-opacity=\"0.843137\" stroke=\"black\" d=\"M609,-461.5C609,-461.5 495,-461.5 495,-461.5 489,-461.5 483,-455.5 483,-449.5 483,-449.5 483,-420.5 483,-420.5 483,-414.5 489,-408.5 495,-408.5 495,-408.5 609,-408.5 609,-408.5 615,-408.5 621,-414.5 621,-420.5 621,-420.5 621,-449.5 621,-449.5 621,-455.5 615,-461.5 609,-461.5\"/>\r\n",
       "<text text-anchor=\"start\" x=\"514.5\" y=\"-446.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.236</text>\r\n",
       "<text text-anchor=\"start\" x=\"500.5\" y=\"-431.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1230</text>\r\n",
       "<text text-anchor=\"start\" x=\"491\" y=\"-416.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1062, 168]</text>\r\n",
       "</g>\r\n",
       "<!-- 1&#45;&gt;11 -->\r\n",
       "<g id=\"edge11\" class=\"edge\"><title>1&#45;&gt;11</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M495.948,-504.884C505.165,-493.556 515.48,-480.88 524.723,-469.521\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"527.637,-471.486 531.234,-461.52 522.207,-467.067 527.637,-471.486\"/>\r\n",
       "</g>\r\n",
       "<!-- 3 -->\r\n",
       "<g id=\"node4\" class=\"node\"><title>3</title>\r\n",
       "<path fill=\"#399de5\" fill-opacity=\"0.400000\" stroke=\"black\" d=\"M374.5,-365C374.5,-365 243.5,-365 243.5,-365 237.5,-365 231.5,-359 231.5,-353 231.5,-353 231.5,-309 231.5,-309 231.5,-303 237.5,-297 243.5,-297 243.5,-297 374.5,-297 374.5,-297 380.5,-297 386.5,-303 386.5,-309 386.5,-309 386.5,-353 386.5,-353 386.5,-359 380.5,-365 374.5,-365\"/>\r\n",
       "<text text-anchor=\"start\" x=\"271\" y=\"-349.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">great ≤ 0.57</text>\r\n",
       "<text text-anchor=\"start\" x=\"271.5\" y=\"-334.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.468</text>\r\n",
       "<text text-anchor=\"start\" x=\"253\" y=\"-319.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 17203</text>\r\n",
       "<text text-anchor=\"start\" x=\"239.5\" y=\"-304.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [6438, 10765]</text>\r\n",
       "</g>\r\n",
       "<!-- 2&#45;&gt;3 -->\r\n",
       "<g id=\"edge3\" class=\"edge\"><title>2&#45;&gt;3</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M361.676,-400.884C355,-392.154 347.713,-382.625 340.746,-373.514\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"343.319,-371.117 334.464,-365.299 337.758,-375.369 343.319,-371.117\"/>\r\n",
       "</g>\r\n",
       "<!-- 10 -->\r\n",
       "<g id=\"node11\" class=\"node\"><title>10</title>\r\n",
       "<path fill=\"#e58139\" fill-opacity=\"0.882353\" stroke=\"black\" d=\"M515,-357.5C515,-357.5 417,-357.5 417,-357.5 411,-357.5 405,-351.5 405,-345.5 405,-345.5 405,-316.5 405,-316.5 405,-310.5 411,-304.5 417,-304.5 417,-304.5 515,-304.5 515,-304.5 521,-304.5 527,-310.5 527,-316.5 527,-316.5 527,-345.5 527,-345.5 527,-351.5 521,-357.5 515,-357.5\"/>\r\n",
       "<text text-anchor=\"start\" x=\"428.5\" y=\"-342.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.186</text>\r\n",
       "<text text-anchor=\"start\" x=\"418.5\" y=\"-327.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 663</text>\r\n",
       "<text text-anchor=\"start\" x=\"413\" y=\"-312.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [594, 69]</text>\r\n",
       "</g>\r\n",
       "<!-- 2&#45;&gt;10 -->\r\n",
       "<g id=\"edge10\" class=\"edge\"><title>2&#45;&gt;10</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M412.649,-400.884C421.423,-389.556 431.24,-376.88 440.038,-365.521\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"442.878,-367.569 446.235,-357.52 437.344,-363.283 442.878,-367.569\"/>\r\n",
       "</g>\r\n",
       "<!-- 4 -->\r\n",
       "<g id=\"node5\" class=\"node\"><title>4</title>\r\n",
       "<path fill=\"#399de5\" fill-opacity=\"0.254902\" stroke=\"black\" d=\"M288,-261C288,-261 166,-261 166,-261 160,-261 154,-255 154,-249 154,-249 154,-205 154,-205 154,-199 160,-193 166,-193 166,-193 288,-193 288,-193 294,-193 300,-199 300,-205 300,-205 300,-249 300,-249 300,-255 294,-261 288,-261\"/>\r\n",
       "<text text-anchor=\"start\" x=\"184.5\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">awful ≤ 1.895</text>\r\n",
       "<text text-anchor=\"start\" x=\"189.5\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.489</text>\r\n",
       "<text text-anchor=\"start\" x=\"171\" y=\"-215.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 12591</text>\r\n",
       "<text text-anchor=\"start\" x=\"162\" y=\"-200.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [5372, 7219]</text>\r\n",
       "</g>\r\n",
       "<!-- 3&#45;&gt;4 -->\r\n",
       "<g id=\"edge4\" class=\"edge\"><title>3&#45;&gt;4</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M282.377,-296.884C275.288,-288.065 267.542,-278.43 260.15,-269.235\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"262.764,-266.9 253.77,-261.299 257.308,-271.286 262.764,-266.9\"/>\r\n",
       "</g>\r\n",
       "<!-- 9 -->\r\n",
       "<g id=\"node10\" class=\"node\"><title>9</title>\r\n",
       "<path fill=\"#399de5\" fill-opacity=\"0.698039\" stroke=\"black\" d=\"M452,-253.5C452,-253.5 330,-253.5 330,-253.5 324,-253.5 318,-247.5 318,-241.5 318,-241.5 318,-212.5 318,-212.5 318,-206.5 324,-200.5 330,-200.5 330,-200.5 452,-200.5 452,-200.5 458,-200.5 464,-206.5 464,-212.5 464,-212.5 464,-241.5 464,-241.5 464,-247.5 458,-253.5 452,-253.5\"/>\r\n",
       "<text text-anchor=\"start\" x=\"353.5\" y=\"-238.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.355</text>\r\n",
       "<text text-anchor=\"start\" x=\"339.5\" y=\"-223.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 4612</text>\r\n",
       "<text text-anchor=\"start\" x=\"326\" y=\"-208.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1066, 3546]</text>\r\n",
       "</g>\r\n",
       "<!-- 3&#45;&gt;9 -->\r\n",
       "<g id=\"edge9\" class=\"edge\"><title>3&#45;&gt;9</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M335.623,-296.884C344.73,-285.556 354.92,-272.88 364.052,-261.521\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"366.946,-263.507 370.484,-253.52 361.491,-259.121 366.946,-263.507\"/>\r\n",
       "</g>\r\n",
       "<!-- 5 -->\r\n",
       "<g id=\"node6\" class=\"node\"><title>5</title>\r\n",
       "<path fill=\"#399de5\" fill-opacity=\"0.305882\" stroke=\"black\" d=\"M212,-157C212,-157 90,-157 90,-157 84,-157 78,-151 78,-145 78,-145 78,-101 78,-101 78,-95 84,-89 90,-89 90,-89 212,-89 212,-89 218,-89 224,-95 224,-101 224,-101 224,-145 224,-145 224,-151 218,-157 212,-157\"/>\r\n",
       "<text text-anchor=\"start\" x=\"105\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">boring ≤ 1.846</text>\r\n",
       "<text text-anchor=\"start\" x=\"113.5\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.484</text>\r\n",
       "<text text-anchor=\"start\" x=\"95\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 12126</text>\r\n",
       "<text text-anchor=\"start\" x=\"86\" y=\"-96.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [4972, 7154]</text>\r\n",
       "</g>\r\n",
       "<!-- 4&#45;&gt;5 -->\r\n",
       "<g id=\"edge5\" class=\"edge\"><title>4&#45;&gt;5</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M202.325,-192.884C195.821,-184.154 188.72,-174.625 181.932,-165.514\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"184.593,-163.227 175.811,-157.299 178.98,-167.409 184.593,-163.227\"/>\r\n",
       "</g>\r\n",
       "<!-- 8 -->\r\n",
       "<g id=\"node9\" class=\"node\"><title>8</title>\r\n",
       "<path fill=\"#e58139\" fill-opacity=\"0.839216\" stroke=\"black\" d=\"M352,-149.5C352,-149.5 254,-149.5 254,-149.5 248,-149.5 242,-143.5 242,-137.5 242,-137.5 242,-108.5 242,-108.5 242,-102.5 248,-96.5 254,-96.5 254,-96.5 352,-96.5 352,-96.5 358,-96.5 364,-102.5 364,-108.5 364,-108.5 364,-137.5 364,-137.5 364,-143.5 358,-149.5 352,-149.5\"/>\r\n",
       "<text text-anchor=\"start\" x=\"269.5\" y=\"-134.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.24</text>\r\n",
       "<text text-anchor=\"start\" x=\"255.5\" y=\"-119.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 465</text>\r\n",
       "<text text-anchor=\"start\" x=\"250\" y=\"-104.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [400, 65]</text>\r\n",
       "</g>\r\n",
       "<!-- 4&#45;&gt;8 -->\r\n",
       "<g id=\"edge8\" class=\"edge\"><title>4&#45;&gt;8</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M251.675,-192.884C260.033,-181.666 269.377,-169.126 277.777,-157.852\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"280.817,-159.63 283.985,-149.52 275.204,-155.448 280.817,-159.63\"/>\r\n",
       "</g>\r\n",
       "<!-- 6 -->\r\n",
       "<g id=\"node7\" class=\"node\"><title>6</title>\r\n",
       "<path fill=\"#399de5\" fill-opacity=\"0.352941\" stroke=\"black\" d=\"M134,-53C134,-53 12,-53 12,-53 6,-53 0,-47 0,-41 0,-41 0,-12 0,-12 0,-6 6,-0 12,-0 12,-0 134,-0 134,-0 140,-0 146,-6 146,-12 146,-12 146,-41 146,-41 146,-47 140,-53 134,-53\"/>\r\n",
       "<text text-anchor=\"start\" x=\"35.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.477</text>\r\n",
       "<text text-anchor=\"start\" x=\"17\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 11549</text>\r\n",
       "<text text-anchor=\"start\" x=\"8\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [4544, 7005]</text>\r\n",
       "</g>\r\n",
       "<!-- 5&#45;&gt;6 -->\r\n",
       "<g id=\"edge6\" class=\"edge\"><title>5&#45;&gt;6</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M123.719,-88.9485C116.244,-79.892 108.136,-70.0682 100.64,-60.9875\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"103.308,-58.721 94.243,-53.2367 97.9094,-63.1769 103.308,-58.721\"/>\r\n",
       "</g>\r\n",
       "<!-- 7 -->\r\n",
       "<g id=\"node8\" class=\"node\"><title>7</title>\r\n",
       "<path fill=\"#e58139\" fill-opacity=\"0.650980\" stroke=\"black\" d=\"M282,-53C282,-53 176,-53 176,-53 170,-53 164,-47 164,-41 164,-41 164,-12 164,-12 164,-6 170,-0 176,-0 176,-0 282,-0 282,-0 288,-0 294,-6 294,-12 294,-12 294,-41 294,-41 294,-47 288,-53 282,-53\"/>\r\n",
       "<text text-anchor=\"start\" x=\"191.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.383</text>\r\n",
       "<text text-anchor=\"start\" x=\"181.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 577</text>\r\n",
       "<text text-anchor=\"start\" x=\"172\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [428, 149]</text>\r\n",
       "</g>\r\n",
       "<!-- 5&#45;&gt;7 -->\r\n",
       "<g id=\"edge7\" class=\"edge\"><title>5&#45;&gt;7</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M178.281,-88.9485C185.756,-79.892 193.864,-70.0682 201.36,-60.9875\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"204.091,-63.1769 207.757,-53.2367 198.692,-58.721 204.091,-63.1769\"/>\r\n",
       "</g>\r\n",
       "</g>\r\n",
       "</svg>\r\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x166b9691438>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_tree = DecisionTreeClassifier(max_depth=6, min_impurity_decrease=0.005)\n",
    "clf_tree.fit(X_train_scaled, y_train)\n",
    "\n",
    "tree_plot = tree.export_graphviz(clf_tree, out_file=None, \n",
    "                                      feature_names=f_names, \n",
    "                                      filled=True, rounded=True, \n",
    "                                      special_characters=True) \n",
    "tree_graph_noz = graphviz.Source(tree_plot)\n",
    "tree_graph_noz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = clf_l2.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 2)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_proba = clf_l2.predict_proba(X_test_scaled)\n",
    "y_pred_proba.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\anne soraya\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1356: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.log(self.predict_proba(X))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(25000, 2)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_log_proba = clf_l2.predict_log_proba(X_test_scaled)\n",
    "y_pred_log_proba.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 10000)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_l2.coef_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.36362513])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_l2.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''Copy the data X and coefficient w_i'''\n",
    "X = np.copy(X_test_scaled)\n",
    "coef_ = np.copy(clf_l2.coef_)\n",
    "n_samples, n_features = X.shape\n",
    "\n",
    "'''Initialize X_ev : x_i * w_i'''\n",
    "X_ev = np.zeros((n_samples, n_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''Get evidence'''\n",
    "'''Calculate the w_ia_i'''\n",
    "for idx in range(n_samples):\n",
    "    X_ev[idx, :] = X[idx,:] * coef_\n",
    "\n",
    "'''Generate the sets of P and N'''\n",
    "X_pos_ev = X_ev * (X_ev > 0)\n",
    "X_neg_ev = X_ev * (X_ev < 0)\n",
    "\n",
    "'''Sum each the set P and N'''\n",
    "pos_ev = np.sum(X_pos_ev, axis=1)\n",
    "neg_ev = np.sum(X_neg_ev, axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The most positive object with respect to the probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "most_pos_obj_idx = np.argmax(y_pred_proba[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index of the object :  12540\n",
      "[-0.05701343 -0.09422382 -0.3958677  ..., -0.07060258 -0.03288111\n",
      " -0.03466182]\n",
      "Class :  1\n",
      "Predict Class :  1\n",
      "a) Total  positive evidence :  118.840235491\n",
      "b) Total negative evidence :  -77.7315148418\n",
      "c) Probability distribution [ 0.  1.]\n",
      "d) Top 10 most positive words values that contribute most to the positive evidence\n",
      "\t hyde \t Value :  19.8953611886 \t Evidence Value :  4.74427589776 \tCoef_ :  0.238461410817\n",
      "\t sunk \t Value :  24.6729831508 \t Evidence Value :  4.54383894931 \tCoef_ :  0.184162527958\n",
      "\t heartbreaking \t Value :  18.6070476493 \t Evidence Value :  3.50346657154 \tCoef_ :  0.188287074746\n",
      "\t jonathan \t Value :  17.0205074665 \t Evidence Value :  3.01615743782 \tCoef_ :  0.17720725682\n",
      "\t paxton \t Value :  21.903635104 \t Evidence Value :  2.94431087185 \tCoef_ :  0.134421106719\n",
      "\t voyage \t Value :  23.0415905184 \t Evidence Value :  2.83224856699 \tCoef_ :  0.122918969709\n",
      "\t survive \t Value :  10.1785318421 \t Evidence Value :  2.66629542209 \tCoef_ :  0.261952849729\n",
      "\t zane \t Value :  21.6955781948 \t Evidence Value :  2.58558383546 \tCoef_ :  0.119175613217\n",
      "\t titanic \t Value :  17.3264196901 \t Evidence Value :  2.14379778784 \tCoef_ :  0.12372999305\n",
      "\t suspense \t Value :  6.15469323635 \t Evidence Value :  1.78453042218 \tCoef_ :  0.289946282235\n",
      "e) Top 10 most negative values that contribute most to the negative evidence\n",
      "\t ill \t Value :  9.44736511315 \t Evidence Value :  -3.60428411359\n",
      "\t combining \t Value :  24.9799919936 \t Evidence Value :  -2.87367622066\n",
      "\t thousands \t Value :  13.0473321684 \t Evidence Value :  -2.55993804167\n",
      "\t slow \t Value :  4.90409015011 \t Evidence Value :  -1.72384217613\n",
      "\t billy \t Value :  9.66124332793 \t Evidence Value :  -1.27689963448\n",
      "\t thats \t Value :  9.10453828866 \t Evidence Value :  -1.27576155959\n",
      "\t making \t Value :  2.9593920932 \t Evidence Value :  -1.18880459765\n",
      "\t bates \t Value :  23.0415905184 \t Evidence Value :  -1.18502846846\n",
      "\t sorry \t Value :  5.79879632175 \t Evidence Value :  -1.18146496484\n",
      "\t added \t Value :  7.64083914258 \t Evidence Value :  -1.04375741132\n"
     ]
    }
   ],
   "source": [
    "print('Index of the object : ', most_pos_obj_idx)\n",
    "print(X_test_scaled[most_pos_obj_idx, :].T)\n",
    "print('Class : ', y_test[most_pos_obj_idx])\n",
    "print('Predict Class : ', y_pred[most_pos_obj_idx])\n",
    "print('a) Total  positive evidence : ', pos_ev[most_pos_obj_idx])\n",
    "print('b) Total negative evidence : ', neg_ev[most_pos_obj_idx])\n",
    "print('c) Probability distribution', y_pred_proba[most_pos_obj_idx])\n",
    "\n",
    "#print(pos_ev[most_pos_obj_idx])\n",
    "feature_pos = X_ev[most_pos_obj_idx,:]\n",
    "pos_list = np.argsort(feature_pos)[::-1]\n",
    "feature_neg = X_ev[most_pos_obj_idx,:]\n",
    "neg_list = np.argsort(feature_neg)\n",
    "#feature_pos = np.multiply(X[most_pos_obj_idx, :], pos_X.T)\n",
    "#pos_list = np.argsort(feature_pos)[::-1]\n",
    "#feature_neg = np.multiply(1-X[most_pos_obj_idx, :], neg_X.T)\n",
    "#neg_list = np.argsort(feature_neg)\n",
    "\n",
    "print('d) Top 10 most positive words values that contribute most to the positive evidence')\n",
    "for i in range(0,10):\n",
    "#    print('\\t',names[pos_list[i]], '\\t Evidence Value : ', np.sort(feature_pos)[::-1][i])\n",
    "     print('\\t',f_names[pos_list[i]], '\\t Value : ', X_test_scaled[most_pos_obj_idx, pos_list[i]], '\\t Evidence Value : ', np.sort(feature_pos)[::-1][i], '\\tCoef_ : ', coef_[0, pos_list[i]])\n",
    "    \n",
    "print('e) Top 10 most negative values that contribute most to the negative evidence')\n",
    "for j in range(0,10):\n",
    "#    print('\\t',names[neg_list[j]], '\\t Evidence Value : ', np.sort(feature_neg)[j])\n",
    "     print('\\t',f_names[neg_list[j]], '\\t Value : ', X_test_scaled[most_pos_obj_idx, neg_list[j]], '\\t Evidence Value : ', np.sort(feature_neg)[j])\n",
    "\n",
    "#print(np.sort(feature_pos)[::-1])     \n",
    "#print(np.sort(feature_neg))\n",
    "#print(pos_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The most negative object with respect to the probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "most_neg_obj_idx = np.argmin(y_pred_proba[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index of the object :  5388\n",
      "[-0.05701343 -0.09422382 -0.3958677  ..., -0.07060258 -0.03288111\n",
      " -0.03466182]\n",
      "Class :  0\n",
      "Predict Class :  0\n",
      "a) Total  positive evidence :  150.059267219\n",
      "b) Total negative evidence :  -262.336086569\n",
      "c) Probability distribution [  1.00000000e+00   1.20469338e-49]\n",
      "d) Top 10 features values that contribute most to the positive evidence\n",
      "\t defending \t Value :  24.6729831508 \t Evidence Value :  5.96255083825\n",
      "\t drain \t Value :  24.9799919936 \t Evidence Value :  4.47009504885\n",
      "\t vet \t Value :  25.6299578002 \t Evidence Value :  3.71228639975\n",
      "\t deciding \t Value :  21.903635104 \t Evidence Value :  3.51175438322\n",
      "\t prolific \t Value :  25.9745197391 \t Evidence Value :  3.12749427398\n",
      "\t attached \t Value :  14.0503629282 \t Evidence Value :  2.80881121425\n",
      "\t helped \t Value :  9.02819200201 \t Evidence Value :  2.77112386632\n",
      "\t uncut \t Value :  20.0555679663 \t Evidence Value :  2.60136022594\n",
      "\t jungle \t Value :  13.8314023984 \t Evidence Value :  2.46733013405\n",
      "\t incompetence \t Value :  27.0978618649 \t Evidence Value :  2.44250066927\n",
      "e) Top 10 features values that contribute most to the negative evidence\n",
      "\t straw \t Value :  27.5059222273 \t Evidence Value :  -7.23259998071\n",
      "\t chewing \t Value :  23.2911627204 \t Evidence Value :  -4.63945175061\n",
      "\t crawl \t Value :  26.7074093518 \t Evidence Value :  -4.2100307635\n",
      "\t poorly \t Value :  6.22459862007 \t Evidence Value :  -4.19296982057\n",
      "\t slightest \t Value :  14.459738366 \t Evidence Value :  -3.97089370921\n",
      "\t unpleasant \t Value :  15.3247856952 \t Evidence Value :  -3.91794068827\n",
      "\t altman \t Value :  21.4933236835 \t Evidence Value :  -3.86587901353\n",
      "\t turkey \t Value :  12.6196834452 \t Evidence Value :  -3.72466997017\n",
      "\t fails \t Value :  6.59423883137 \t Evidence Value :  -3.69151687545\n",
      "\t rat \t Value :  18.4787919904 \t Evidence Value :  -3.59538435319\n"
     ]
    }
   ],
   "source": [
    "print('Index of the object : ', most_neg_obj_idx)\n",
    "print(X_test_scaled[most_neg_obj_idx, :])\n",
    "print('Class : ', y_test[most_neg_obj_idx])\n",
    "print('Predict Class : ', y_pred[most_neg_obj_idx])\n",
    "print('a) Total  positive evidence : ', pos_ev[most_neg_obj_idx])\n",
    "print('b) Total negative evidence : ', neg_ev[most_neg_obj_idx])\n",
    "print('c) Probability distribution', y_pred_proba[most_neg_obj_idx])\n",
    "\n",
    "feature_pos = X_ev[most_neg_obj_idx,:]\n",
    "pos_list = np.argsort(feature_pos)[::-1]\n",
    "feature_neg = X_ev[most_neg_obj_idx,:]\n",
    "neg_list = np.argsort(feature_neg)\n",
    "#feature_pos = np.multiply(X[most_neg_obj_idx, :], pos_X.T)\n",
    "#pos_list = np.argsort(feature_pos)[::-1]\n",
    "#feature_neg = np.multiply(1-X[most_neg_obj_idx, :], neg_X.T)\n",
    "#neg_list = np.argsort(feature_neg)\n",
    "\n",
    "print('d) Top 10 features values that contribute most to the positive evidence')\n",
    "for i in range(0,10):\n",
    "#    print('\\t',pos_list[i], '\\t Evidence Value : ', np.sort(feature_pos)[::-1][i])\n",
    "    print('\\t',f_names[pos_list[i]], '\\t Value : ', X_test_scaled[most_neg_obj_idx, pos_list[i]], '\\t Evidence Value : ', np.sort(feature_pos)[::-1][i])\n",
    "\n",
    "    \n",
    "print('e) Top 10 features values that contribute most to the negative evidence')\n",
    "for j in range(0,10):\n",
    "#    print('\\t',neg_list[j], '\\t Evidence Value : ', np.sort(feature_neg)[j])\n",
    "    print('\\t',f_names[neg_list[j]], '\\t Value : ', X_test_scaled[most_neg_obj_idx, neg_list[j]], '\\t Evidence Value : ', np.sort(feature_neg)[j])\n",
    "\n",
    "    \n",
    "#print(np.sort(feature_pos)[::-1])     \n",
    "#print(np.sort(feature_neg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The object that has the largest positive evidence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "most_pos_ev_idx = np.argmax(pos_ev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index of the object :  16846\n",
      "[-0.05701343 -0.09422382 -0.3958677  ..., -0.07060258 -0.03288111\n",
      " -0.03466182]\n",
      "Class :  1\n",
      "Predict Class :  1\n",
      "a) Total  positive log-evidence :  340.616885225\n",
      "b) Total negative log-evidence :  -268.113992102\n",
      "c) Probability distribution [ 0.  1.]\n",
      "d) Top 10 features values that contribute most to the positive evidence\n",
      "\t scariest \t Value :  20.5603699762 \t Evidence Value :  8.52340251342\n",
      "\t architecture \t Value :  27.9329554469 \t Evidence Value :  8.2734180702\n",
      "\t bartender \t Value :  28.380479434 \t Evidence Value :  8.00693715322\n",
      "\t alcoholism \t Value :  26.7074093518 \t Evidence Value :  5.20599591304\n",
      "\t psyche \t Value :  21.903635104 \t Evidence Value :  4.26647960916\n",
      "\t patients \t Value :  19.4367661608 \t Evidence Value :  4.13632946582\n",
      "\t spring \t Value :  15.5472970835 \t Evidence Value :  4.10981116117\n",
      "\t crown \t Value :  23.0415905184 \t Evidence Value :  4.10028206106\n",
      "\t stanley \t Value :  14.7749194791 \t Evidence Value :  3.90051246957\n",
      "\t imaginary \t Value :  23.0415905184 \t Evidence Value :  3.61448605183\n",
      "e) Top 10 features values that contribute most to the negative evidence\n",
      "\t projection \t Value :  28.8501877521 \t Evidence Value :  -7.56576788264\n",
      "\t 98 \t Value :  25.9745197391 \t Evidence Value :  -6.45742364841\n",
      "\t stares \t Value :  25.9745197391 \t Evidence Value :  -6.22306522542\n",
      "\t documented \t Value :  29.343976648 \t Evidence Value :  -4.72232848378\n",
      "\t clockwork \t Value :  27.9329554469 \t Evidence Value :  -4.31364456587\n",
      "\t approaching \t Value :  21.2966066439 \t Evidence Value :  -4.23618624914\n",
      "\t butchered \t Value :  25.6299578002 \t Evidence Value :  -4.14081360404\n",
      "\t axe \t Value :  21.6955781948 \t Evidence Value :  -3.80211834706\n",
      "\t spoke \t Value :  17.0205074665 \t Evidence Value :  -3.69709340595\n",
      "\t obnoxious \t Value :  12.7018763314 \t Evidence Value :  -3.62207240016\n"
     ]
    }
   ],
   "source": [
    "print('Index of the object : ', most_pos_ev_idx)\n",
    "print(X_test_scaled[most_pos_ev_idx, :])\n",
    "print('Class : ', y_test[most_pos_ev_idx])\n",
    "print('Predict Class : ', y_pred[most_pos_ev_idx])\n",
    "print('a) Total  positive log-evidence : ', pos_ev[most_pos_ev_idx])\n",
    "print('b) Total negative log-evidence : ', neg_ev[most_pos_ev_idx])\n",
    "print('c) Probability distribution', y_pred_proba[most_pos_ev_idx])\n",
    "\n",
    "feature_pos = X_ev[most_pos_ev_idx,:]\n",
    "pos_list = np.argsort(feature_pos)[::-1]\n",
    "feature_neg = X_ev[most_pos_ev_idx,:]\n",
    "neg_list = np.argsort(feature_neg)\n",
    "\n",
    "print('d) Top 10 features values that contribute most to the positive evidence')\n",
    "for i in range(0,10):\n",
    "#    print('\\t',pos_list[i], '\\t Evidence Value : ', np.sort(feature_pos)[::-1][i])\n",
    "    print('\\t',f_names[pos_list[i]], '\\t Value : ', X_test_scaled[most_pos_ev_idx, pos_list[i]], '\\t Evidence Value : ', np.sort(feature_pos)[::-1][i]) \n",
    "\n",
    "print('e) Top 10 features values that contribute most to the negative evidence')\n",
    "for j in range(0,10):\n",
    "#    print('\\t',neg_list[j], '\\t Evidence Value : ', np.sort(feature_neg)[j])\n",
    "    print('\\t',f_names[neg_list[j]], '\\t Value : ', X_test_scaled[most_pos_ev_idx, neg_list[j]], '\\t Evidence Value : ', np.sort(feature_neg)[j])\n",
    "\n",
    "    \n",
    "#print(np.sort(feature_pos)[::-1])     \n",
    "#print(np.sort(feature_neg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The object that has the largest negative evidence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "most_neg_ev_idx = np.argmin(neg_ev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index of the object :  4700\n",
      "[ -0.05701343  -0.09422382   2.52609645 ...,  14.16378845  -0.03288111\n",
      "  -0.03466182]\n",
      "Class :  0\n",
      "Predict Class :  0\n",
      "a) Total  positive log-evidence :  218.158125081\n",
      "b) Total negative log-evidence :  -294.394688462\n",
      "c) Probability distribution [  1.00000000e+00   5.40705537e-34]\n",
      "d) Top 10 features values that contribute most to the positive evidence\n",
      "\t apocalyptic \t Value :  23.5490032816 \t Evidence Value :  8.81461923091\n",
      "\t abandoned \t Value :  11.8424211145 \t Evidence Value :  4.78346288828\n",
      "\t shed \t Value :  18.3531424513 \t Evidence Value :  3.88686739447\n",
      "\t funniest \t Value :  8.64624633917 \t Evidence Value :  3.52033187703\n",
      "\t stack \t Value :  23.0415905184 \t Evidence Value :  2.97675139801\n",
      "\t perfect \t Value :  4.17246038039 \t Evidence Value :  2.93797126939\n",
      "\t infested \t Value :  30.4125948568 \t Evidence Value :  2.86648786701\n",
      "\t continues \t Value :  9.90991166491 \t Evidence Value :  2.73441762429\n",
      "\t hello \t Value :  18.2300118852 \t Evidence Value :  2.72877157276\n",
      "\t lucio \t Value :  29.8639773449 \t Evidence Value :  2.67702171979\n",
      "e) Top 10 features values that contribute most to the negative evidence\n",
      "\t unimaginative \t Value :  20.3879049112 \t Evidence Value :  -6.08919508175\n",
      "\t boom \t Value :  17.7610724958 \t Evidence Value :  -5.14513944969\n",
      "\t disappointment \t Value :  7.96448301466 \t Evidence Value :  -5.13761713458\n",
      "\t fest \t Value :  13.8314023984 \t Evidence Value :  -4.75835503764\n",
      "\t rusty \t Value :  27.9329554469 \t Evidence Value :  -4.52024927749\n",
      "\t laughable \t Value :  7.85217432333 \t Evidence Value :  -4.45804628578\n",
      "\t clothing \t Value :  15.8595476772 \t Evidence Value :  -4.13684136617\n",
      "\t franchise \t Value :  13.8851881375 \t Evidence Value :  -4.02007492177\n",
      "\t introduction \t Value :  12.4599357944 \t Evidence Value :  -3.35291584997\n",
      "\t inept \t Value :  12.2312063852 \t Evidence Value :  -3.27815435533\n"
     ]
    }
   ],
   "source": [
    "print('Index of the object : ', most_neg_ev_idx)\n",
    "print(X_test_scaled[most_neg_ev_idx, :])\n",
    "print('Class : ', y_test[most_neg_ev_idx])\n",
    "print('Predict Class : ', y_pred[most_neg_ev_idx])\n",
    "print('a) Total  positive log-evidence : ', pos_ev[most_neg_ev_idx])\n",
    "print('b) Total negative log-evidence : ', neg_ev[most_neg_ev_idx])\n",
    "print('c) Probability distribution', y_pred_proba[most_neg_ev_idx])\n",
    "\n",
    "feature_pos = X_ev[most_neg_ev_idx,:]\n",
    "pos_list = np.argsort(feature_pos)[::-1]\n",
    "feature_neg = X_ev[most_neg_ev_idx,:]\n",
    "neg_list = np.argsort(feature_neg)\n",
    "\n",
    "print('d) Top 10 features values that contribute most to the positive evidence')\n",
    "for i in range(0,10):\n",
    "#    print('\\t',pos_list[i], '\\t Evidence Value : ', np.sort(feature_pos)[::-1][i])\n",
    "    print('\\t',f_names[pos_list[i]], '\\t Value : ', X_test_scaled[most_neg_ev_idx, pos_list[i]], '\\t Evidence Value : ', np.sort(feature_pos)[::-1][i])  \n",
    "\n",
    "print('e) Top 10 features values that contribute most to the negative evidence')\n",
    "for j in range(0,10):\n",
    "#    print('\\t',neg_list[j], '\\t Evidence Value : ', np.sort(feature_neg)[j])\n",
    "    print('\\t',f_names[neg_list[j]], '\\t Value : ', X_test_scaled[most_neg_ev_idx, neg_list[j]], '\\t Evidence Value : ', np.sort(feature_neg)[j])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The most uncertain object with respect to the probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "uncertain_idx = np.argmin(np.square(y_pred_proba[:,1]-0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index of the object :  17496\n",
      "[-0.05701343 -0.09422382 -0.3958677  ..., -0.07060258 -0.03288111\n",
      " -0.03466182]\n",
      "Class :  1\n",
      "Predict Class :  1\n",
      "a) Total  positive evidence :  50.7076723418\n",
      "b) Total negative evidence :  -48.1911462172\n",
      "c) Probability distribution [ 0.10406045  0.89593955]\n",
      "d) Top 10 features values that contribute most to the positive evidence\n",
      "\t well \t Value :  1.52259331956 \t Evidence Value :  0.785022963667\n",
      "\t bad \t Value :  -0.556034797717 \t Evidence Value :  0.642205099226\n",
      "\t know \t Value :  2.05619505427 \t Evidence Value :  0.562616779856\n",
      "\t was \t Value :  -1.35264732363 \t Evidence Value :  0.506115646954\n",
      "\t not \t Value :  -1.21864246735 \t Evidence Value :  0.437237464794\n",
      "\t worst \t Value :  -0.315942446627 \t Evidence Value :  0.420674842992\n",
      "\t just \t Value :  -0.854741399668 \t Evidence Value :  0.364632166652\n",
      "\t br \t Value :  -1.19130128908 \t Evidence Value :  0.351958959116\n",
      "\t tired \t Value :  8.32013936789 \t Evidence Value :  0.305935472843\n",
      "\t no \t Value :  -0.699208737982 \t Evidence Value :  0.281447625258\n",
      "e) Top 10 features values that contribute most to the negative evidence\n",
      "\t great \t Value :  -0.581230106654 \t Evidence Value :  -0.5506095591\n",
      "\t is \t Value :  -2.95169607387 \t Evidence Value :  -0.462140100798\n",
      "\t you \t Value :  -1.09497127355 \t Evidence Value :  -0.445766017857\n",
      "\t best \t Value :  -0.49380459421 \t Evidence Value :  -0.349694169632\n",
      "\t good \t Value :  -0.792281602323 \t Evidence Value :  -0.309726549907\n",
      "\t don \t Value :  1.68951346572 \t Evidence Value :  -0.29738735713\n",
      "\t most \t Value :  -0.593550012512 \t Evidence Value :  -0.287901422669\n",
      "\t film \t Value :  -1.12294751622 \t Evidence Value :  -0.284436527766\n",
      "\t excellent \t Value :  -0.276871907933 \t Evidence Value :  -0.257079954219\n",
      "\t the \t Value :  -10.9440827327 \t Evidence Value :  -0.246006408613\n"
     ]
    }
   ],
   "source": [
    "print('Index of the object : ', uncertain_idx)\n",
    "print(X_test_scaled[uncertain_idx, :])\n",
    "print('Class : ', y_test[uncertain_idx])\n",
    "print('Predict Class : ', y_pred[uncertain_idx])\n",
    "\n",
    "if y_test[uncertain_idx] != y_pred[uncertain_idx]:\n",
    "    print('\\t \\t \\t \\t \\t False Positive')\n",
    "\n",
    "print('a) Total  positive evidence : ', pos_ev[uncertain_idx])\n",
    "print('b) Total negative evidence : ', neg_ev[uncertain_idx])\n",
    "print('c) Probability distribution', y_pred_proba[uncertain_idx])\n",
    "\n",
    "feature_pos = X_ev[uncertain_idx,:]\n",
    "pos_list = np.argsort(feature_pos)[::-1]\n",
    "feature_neg = X_ev[uncertain_idx,:]\n",
    "neg_list = np.argsort(feature_neg)\n",
    "\n",
    "print('d) Top 10 features values that contribute most to the positive evidence')\n",
    "for i in range(0,10):\n",
    "#    print('\\t',pos_list[i], '\\t Evidence Value : ', np.sort(feature_pos)[::-1][i])\n",
    "    print('\\t',f_names[pos_list[i]], '\\t Value : ', X_test_scaled[uncertain_idx, pos_list[i]], '\\t Evidence Value : ', np.sort(feature_pos)[::-1][i])   \n",
    "\n",
    "print('e) Top 10 features values that contribute most to the negative evidence')\n",
    "for j in range(0,10):\n",
    "#    print('\\t',neg_list[j], '\\t Evidence Value : ', np.sort(feature_neg)[j])\n",
    "    print('\\t',f_names[neg_list[j]], '\\t Value : ', X_test_scaled[uncertain_idx, neg_list[j]], '\\t Evidence Value : ', np.sort(feature_neg)[j])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
